{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import util_mnist_reader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n",
    "#Loading Dataset                            \n",
    "X_train, y_train = util_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = util_mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "\n",
    "labelNames =  np.array(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'])\n",
    "labels=10\n",
    "\n",
    "#Normalizing and Reshaping\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hidden Layer Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_train = y_train.shape[0]\n",
    "examples_test = y_test.shape[0]\n",
    "\n",
    "#Reshaping\n",
    "y_train_reshape = y_train.reshape(1, examples_train)\n",
    "y_test_reshape = y_test.reshape(1, examples_test)\n",
    "\n",
    "y_train_NN= np.eye(labels)[y_train_reshape.astype('int32')]\n",
    "y_train_NN=y_train_NN.astype('int32')\n",
    "y_train_NN = y_train_NN.T.reshape(labels, examples_train)\n",
    "\n",
    "y_test_NN = np.eye(labels)[y_test_reshape.astype('int32')]\n",
    "y_test_NN=y_test_NN.astype('int32')\n",
    "y_test_NN = y_test_NN.T.reshape(labels, examples_test)\n",
    "\n",
    "#Shuffling\n",
    "m1 = 60000\n",
    "m2 = 10000\n",
    "\n",
    "X_train = X_train[:m1].T\n",
    "X_test = X_test[:m2].T\n",
    "\n",
    "shuffle_index = np.random.permutation(m1)\n",
    "X_train, y_train_NN = X_train[:, shuffle_index], y_train_NN[:, shuffle_index]\n",
    "shuffle_index = np.random.permutation(m2)\n",
    "X_test, y_test_NN = X_test[:, shuffle_index], y_test_NN[:, shuffle_index]\n",
    "\n",
    "#Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "#Loss Function\n",
    "def compute_loss(Y, Y_hat):\n",
    "\n",
    "    L_sum = np.sum(np.multiply(Y, np.log(Y_hat)))\n",
    "    m = Y.shape[1]\n",
    "    L = -(1/m) * L_sum\n",
    "\n",
    "    return L\n",
    "\n",
    "n_x = X_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 0.5\n",
    "\n",
    "W1 = np.random.randn(n_h, n_x)\n",
    "b1 = np.zeros((n_h, 1))\n",
    "W2 = np.random.randn(labels, n_h)\n",
    "b2 = np.zeros((labels, 1))\n",
    "\n",
    "losstrack=[]\n",
    "for i in range(2000):\n",
    "\n",
    "    Z1 = np.matmul(W1,X_train) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.matmul(W2,A1) + b2\n",
    "    A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "    cost = compute_loss(y_train_NN, A2)\n",
    "    losstrack.append(cost)\n",
    "\n",
    "    dZ2 = A2-y_train_NN\n",
    "    dW2 = (1./m1) * np.matmul(dZ2, A1.T)\n",
    "    db2 = (1./m1) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dS1 = np.matmul(W2.T, dZ2)\n",
    "    dZ1 = dS1 * sigmoid(Z1) * (1 - sigmoid(Z1))\n",
    "    dW1 = (1./m1) * np.matmul(dZ1, X_train.T)\n",
    "    db1 = (1./m1) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "\n",
    "    if (i % 100 == 0):\n",
    "        print(\"Cost of Epoch\", i, \": \", cost)\n",
    "\n",
    "print(\"Final cost:\", cost)\n",
    "\n",
    "#Confusion-matrix and Classification Report\n",
    "Z1 = np.matmul(W1, X_test) + b1\n",
    "A1 = sigmoid(Z1)\n",
    "Z2 = np.matmul(W2, A1) + b2\n",
    "A2 = np.exp(Z2) / np.sum(np.exp(Z2), axis=0)\n",
    "\n",
    "\n",
    "predictions = np.argmax(A2, axis=0)\n",
    "\n",
    "print(confusion_matrix(predictions, np.argmax(y_test_NN, axis=0)))\n",
    "print(classification_report(predictions, np.argmax(y_test_NN, axis=0)))\n",
    "\n",
    "\n",
    "#Plotting Loss and Accuracy Graph\n",
    "plt.plot(losstrack)\n",
    "plt.title('Cost VS Iterations')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Cost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Convolution Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "X_test = X_test.reshape([-1, 28, 28, 1])\n",
    "\n",
    "# Modelling 3-layer neural network\n",
    "model_3 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28,1]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "    \n",
    "model_3.summary() \n",
    "\n",
    "# Compile the model\n",
    "model_3.compile(optimizer=keras.optimizers.Adam(1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the NN-3 with 10 epochs\n",
    "N1 = 10  \n",
    "A1=model_3.fit(X_train, y_train, epochs=N1, validation_split=0.1)\n",
    "\n",
    "#Evaluate the model\n",
    "test_loss, test_acc = model_3.evaluate(X_test, y_test)\n",
    "print(\"Model - 3 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 3 layers - test accuracy:\", test_acc * 100)\n",
    "\n",
    "#Confusion-Matrix and Classification Report\n",
    "predictions_3=model_3.predict(X_test)\n",
    "predictions_3=np.argmax(predictions_3, axis=1)\n",
    "\n",
    "print(confusion_matrix(predictions_3, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "print(classification_report(predictions_3, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "\n",
    "#Plotting Loss and Accuracy Graph\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N1), A1.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N1), A1.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N1), A1.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N1), A1.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Loss and Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "\n",
    "# Modelling 6-layer neural network \n",
    "model_6 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28,1]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "    \n",
    "model_6.summary() \n",
    "\n",
    "model_6.compile(optimizer=keras.optimizers.Adam(1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the NN-6 with 10 epochs \n",
    "N2 = 10\n",
    "A2=model_6.fit(X_train, y_train, epochs=N2, validation_split=0.1)\n",
    "\n",
    "#Evaluate the model\n",
    "test_loss, test_acc = model_6.evaluate(X_test, y_test)\n",
    "print(\"Model - 6 layers - test loss:\", test_loss * 100)\n",
    "print(\"Model - 6 layers - test accuracy:\", test_acc * 100)\n",
    "\n",
    "#Confusion-Matrix and Classification Report\n",
    "predictions_6=model_6.predict(X_test)\n",
    "predictions_6=np.argmax(predictions_6, axis=1)\n",
    "\n",
    "print(confusion_matrix(predictions_6, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "print(classification_report(predictions_6, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "\n",
    "#Plotting Loss and Accuracy Graph\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N2), A2.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N2), A2.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N2), A2.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N2), A2.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Loss and Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "\n",
    "\n",
    "# Modelling 12-layer neural network \n",
    "model_12 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28,1]),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "    \n",
    "model_12.summary()\n",
    " \n",
    "model_12.compile(optimizer=keras.optimizers.Adam(1e-4),loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#Train the NN-12 with 10 epochs\n",
    "N3 = 10\n",
    "A3=model_12.fit(X_train, y_train, epochs=N3, validation_split=0.1)\n",
    "\n",
    "#Evaluate the model\n",
    "test_loss, test_acc = model_12.evaluate(X_test, y_test)\n",
    "print(\"Model - 12 layers - Test loss:\", test_loss * 100)\n",
    "print(\"Model - 12 layers - Test accuracy:\", test_acc * 100)\n",
    "\n",
    "#Confusion-Matrix and Classification Report\n",
    "predictions_12=model_12.predict(X_test)\n",
    "predictions_12=np.argmax(predictions_12, axis=1)\n",
    "\n",
    "print(confusion_matrix(predictions_12, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "print(classification_report(predictions_12, keras.utils.np_utils.to_categorical(y_test).argmax(axis=1)))\n",
    "\n",
    "#Plotting Loss and Accuracy Graph\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N3), A3.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N3), A3.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N3), A3.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N3), A3.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Loss and Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot Encoding\n",
    "y_train_CNN = keras.utils.np_utils.to_categorical(y_train)\n",
    "y_test_CNN = keras.utils.np_utils.to_categorical(y_test)\n",
    "\n",
    "#Keras Convolution Model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (5, 5), padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (5, 5), padding=\"same\"),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "N_epochs=20\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(1e-4),metrics=['accuracy'])\n",
    "\n",
    "A=model.fit(X_train, y_train_CNN, validation_split=0.10, batch_size=128, epochs=N_epochs, verbose=2)\n",
    "\n",
    "#Calculating Test-Loss and Accuracy\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test_CNN, verbose=0)\n",
    "print(\"Test loss: \", test_loss*100)\n",
    "print(\"Test accuracy: \",test_accuracy*100)\n",
    "\n",
    "#Confusion-Matrix and Classification Report\n",
    "predictions_cnn=model.predict(X_test)\n",
    "predictions_cnn=np.argmax(predictions_cnn, axis=1)\n",
    "\n",
    "print(confusion_matrix(predictions_cnn, y_test_CNN.argmax(axis=1)))\n",
    "print(classification_report(predictions_cnn, y_test_CNN.argmax(axis=1)))\n",
    "\n",
    "\n",
    "#Plotting Loss and Accuracy Graph\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N_epochs), A.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N_epochs), A.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N_epochs), A.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N_epochs), A.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Loss and Accuracy\")\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
